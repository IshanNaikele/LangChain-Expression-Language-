{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb17d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8edb4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY loaded successfully!\n",
      "Your key starts with: gsk_...\n"
     ]
    }
   ],
   "source": [
    "if GROQ_API_KEY:\n",
    "    # For security, you might only want to print the first few characters\n",
    "    print(\"GROQ_API_KEY loaded successfully!\")\n",
    "    print(f\"Your key starts with: {GROQ_API_KEY[:4]}...\") \n",
    "else:\n",
    "    print(\"Error: GROQ_API_KEY not found.\")\n",
    "    print(\"Please make sure you have a .env file in the same directory as your script,\")\n",
    "    print(\"and that it contains the line: GROQ_API_KEY='your_actual_key_here'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89103dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000276331E7850>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000027630FBE610>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"openai/gpt-oss-120b\",groq_api_key=GROQ_API_KEY)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1179aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"Translate the following from English to Hindi .\"),\n",
    "    HumanMessage(content=\"Hey Bro,How are you ?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b1b48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='अरे भाई, तुम कैसे हो?', additional_kwargs={'reasoning_content': 'The user asks: \"Translate the following from English to Hindi . Hey Bro,How are you ?\" So we need to provide Hindi translation. Probably \"हे ब्रो, आप कैसे हैं?\" Or \"अरे भाई, तुम कैसे हो?\" Since informal \"Bro\" maybe \"भाई\". So translation: \"अरे भाई, तुम कैसे हो?\" Provide translation.'}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 89, 'total_tokens': 180, 'completion_time': 0.181107257, 'prompt_time': 0.003118684, 'queue_time': 0.046180386, 'total_time': 0.184225941}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e10890e4b9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--232ab3dd-be05-4b83-8a91-4904d71da990-0', usage_metadata={'input_tokens': 89, 'output_tokens': 91, 'total_tokens': 180})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28efc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey there!\\u202fIt looks like you might be looking for some information or just checking in. What’s on your mind? Let me know what you’d like to talk about—whether it’s a specific topic, a question you have, or just a quick chat—and I’ll do my best to help!', additional_kwargs={'reasoning_content': 'The user asks \"What\\'s going on ?\" It\\'s a vague question. We need to respond helpfully, asking for clarification or offering possible interpretations. Should we ask what context? Probably respond: \"Hey! How can I help? What do you want to know?\" Provide friendly tone.'}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 75, 'total_tokens': 203, 'completion_time': 0.254434746, 'prompt_time': 0.002631221, 'queue_time': 0.047515226, 'total_time': 0.257065967}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e10890e4b9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--27ed12f2-8b26-4009-bc90-b3b665e57fd8-0', usage_metadata={'input_tokens': 75, 'output_tokens': 128, 'total_tokens': 203})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What's Going on ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a517663",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.invoke(\"Are you a Open Source Model or a Propierity Model ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302a5ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’m based on OpenAI’s proprietary models (like GPT‑4). While OpenAI shares research and some tools publicly, the core model weights and architecture are not open‑source.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b8e5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अरे भाई, तुम कैसे हो?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bed67f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "\n",
    "generic_template=\"Translate the following into {language}:\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",generic_template),(\"user\",\"{text}\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6da4a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=prompt.invoke({\"language\":\"Marathi\",\"text\":\"Consistency + Dedication + Hardwork + Disclipline + Focus === Success\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88c1bca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into Marathi:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Consistency + Dedication + Hardwork + Disclipline + Focus === Success', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35291a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'सततता\\u202f+\\u202fसमर्पण\\u202f+\\u202fकठोर\\u202fपरिश्रम\\u202f+\\u202fशिस्त\\u202f+\\u202fलक्ष\\u202f===\\u202fयश'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= prompt | model |  parser \n",
    "chain.invoke({\"language\":\"Marathi\",\"text\":\"Consistency + Dedication + Hardwork + Disclipline + Focus === Success\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b30dd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**लगातारता\\u202f+\\u202fसमर्पण\\u202f+\\u202fकड़ी मेहनत\\u202f+\\u202fअनुशासन\\u202f+\\u202fएकाग्रता\\u202f=\\u202fसफलता**'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= prompt | model |  parser \n",
    "chain.invoke({\"language\":\"Hindi\",\"text\":\"Consistency + Dedication + Hardwork + Disclipline + Focus === Success\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2892f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
